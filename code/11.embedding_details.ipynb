{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\pytorch1_13\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- embedding 的计算过程\n",
    "    + 表是matrix\n",
    "    + 索引方式：one hot+矩阵乘法\n",
    "    + input shape:(b,s)\n",
    "    + embedding(input):(b,s,h)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 简单前向"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(10,3) # nxm\n",
    "# 假装构造一个vocab,其中有10个word，每个word用一个3d的向量表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.4422, -1.4363, -0.4358],\n",
       "        [-1.6103, -1.4728,  0.9453],\n",
       "        [-0.6646,  0.8704, -1.1941],\n",
       "        [-0.3679, -0.6565, -0.8222],\n",
       "        [ 0.1443, -0.2155, -1.8041],\n",
       "        [-0.9040, -1.9084, -0.2792],\n",
       "        [ 0.3402, -1.6956, -0.5691],\n",
       "        [ 1.3087,  0.5668, -1.4190],\n",
       "        [-1.1967,  0.0046, -0.9748],\n",
       "        [ 0.2155, -0.1001,  1.6694]], requires_grad=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.weight "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.LongTensor([[1,2,4,5],[4,3,2,8]]) # input是indices  表示两个sentence，每个sentence由四个单词构成2x4 bxs\n",
    "inputs.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-1.6103, -1.4728,  0.9453],\n",
       "          [-0.6646,  0.8704, -1.1941],\n",
       "          [ 0.1443, -0.2155, -1.8041],\n",
       "          [-0.9040, -1.9084, -0.2792]],\n",
       " \n",
       "         [[ 0.1443, -0.2155, -1.8041],\n",
       "          [-0.3679, -0.6565, -0.8222],\n",
       "          [-0.6646,  0.8704, -1.1941],\n",
       "          [-1.1967,  0.0046, -0.9748]]], grad_fn=<EmbeddingBackward0>),\n",
       " torch.Size([2, 4, 3]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding(inputs), embedding(inputs).shape # bxsxm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 one-hot 矩阵算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]]]),\n",
       " torch.Size([2, 4, 10]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_onehot = F.one_hot(inputs, num_classes=10)\n",
    "input_onehot, input_onehot.shape# 2x4——>2x4x10 # 把每一个单索引扩充为01向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32,\n",
       " Parameter containing:\n",
       " tensor([[-0.4422, -1.4363, -0.4358],\n",
       "         [-1.6103, -1.4728,  0.9453],\n",
       "         [-0.6646,  0.8704, -1.1941],\n",
       "         [-0.3679, -0.6565, -0.8222],\n",
       "         [ 0.1443, -0.2155, -1.8041],\n",
       "         [-0.9040, -1.9084, -0.2792],\n",
       "         [ 0.3402, -1.6956, -0.5691],\n",
       "         [ 1.3087,  0.5668, -1.4190],\n",
       "         [-1.1967,  0.0046, -0.9748],\n",
       "         [ 0.2155, -0.1001,  1.6694]], requires_grad=True))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.weight.dtype,embedding.weight # 单词向量表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_onehot.type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.6103, -1.4728,  0.9453],\n",
       "         [-0.6646,  0.8704, -1.1941],\n",
       "         [ 0.1443, -0.2155, -1.8041],\n",
       "         [-0.9040, -1.9084, -0.2792]],\n",
       "\n",
       "        [[ 0.1443, -0.2155, -1.8041],\n",
       "         [-0.3679, -0.6565, -0.8222],\n",
       "         [-0.6646,  0.8704, -1.1941],\n",
       "         [-1.1967,  0.0046, -0.9748]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(input_onehot.type(torch.float32), embedding.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.1346, grad_fn=<MeanBackward0>),\n",
       " tensor(1.0137, grad_fn=<StdBackward0>),\n",
       " Parameter containing:\n",
       " tensor([[-0.4547,  1.1200, -1.5495,  1.4884, -0.6632],\n",
       "         [-0.1234, -0.7767, -0.1438,  0.0704, -0.5591],\n",
       "         [ 1.5854, -1.1521, -0.7820, -1.2070,  1.1288]], requires_grad=True))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = nn.Embedding(3,5,)\n",
    "embedding.weight.mean(),embedding.weight.std(),embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2.5529, 0.9781, 2.6802], grad_fn=<NormBackward1>),\n",
       " tensor([1.6539, 1.7847, 1.7416, 1.9176, 1.4236], grad_fn=<NormBackward1>))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(embedding.weight, dim=1), torch.norm(embedding.weight, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0374, grad_fn=<MeanBackward0>),\n",
       " tensor(1.2599, grad_fn=<StdBackward0>),\n",
       " Parameter containing:\n",
       " tensor([[-1.6550,  0.9733, -2.0622,  2.5498,  1.8684],\n",
       "         [ 1.1724, -0.3173, -0.3685,  0.3944, -0.1885],\n",
       "         [ 0.6279, -0.6441, -0.6993, -1.1012,  0.0101]], requires_grad=True))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embedding = nn.Embedding(3,5,max_norm=True)\n",
    "embedding = nn.Embedding(3,5,max_norm=3)\n",
    "embedding.weight.mean(),embedding.weight.std(),embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch1_13",
   "language": "python",
   "name": "pytorch1_13"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
