{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset：一个标准数据集类\n",
    "- 根据数据的特点和需求创建自己的数据集类流程：\n",
    "    + 继承torch.utils.data.Dataset类\n",
    "    + 实现两个必要方法 _ _len_ _ & _ _getitem_ _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,data,labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, index):\n",
    "        image = self.data[index]\n",
    "        label = self.labels[index]\n",
    "        \"\"\"必要的数据转换与预处理操作\"\"\"\n",
    "        return image, label\n",
    "    \n",
    "''' \n",
    "data = ...\n",
    "labels = ...\n",
    "'''\n",
    "custom_dataset = CustomDataset(data, labels)\n",
    "\n",
    "# 创建数据加载器\n",
    "batch_size = 32\n",
    "shuffle = True\n",
    "num_workers = 4\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    custom_dataset, batch_size=batch_size, \n",
    "    shuffle=shuffle, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- torchvision.datasets.CIFAR10\n",
    "    + 下载标准数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset：一个标准数据集类\n",
    "- 根据数据的特点和需求创建自己的数据集类流程：\n",
    "    + 继承torch.utils.data.Dataset类\n",
    "    + 实现两个必要方法 _ _len_ _ & _ _getitem_ _"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- torch.utils.data.DataLoader\n",
    "    + 输入标准数据集dataset\n",
    "    + 返回数据加载器dataloader\n",
    "    + dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_cifar10(is_train, augs, batch_size):\n",
    "    dataset = torchvision.datasets.CIFAR10(root=\"..\\data\", train=is_train,\n",
    "              transform=augs, download=True) \n",
    "    # is_train指示是否加载训练集True则训练集，False则测试集；\n",
    "    # augs是之前定义的数据处理方法；\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=is_train,num_workers=4)\n",
    "    # shuffle=is_train 每个epoch数据洗牌\n",
    "    # num_workers指定用于数据加载的线程数/核数。这里表示使用 4 个线程进行数据加载\n",
    "    # 返回 dataloader：将创建的数据加载器返回\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train_iter: training data iterator\n",
    "    +  an iterator that *yields batches!* of training data during *each iteration*.\n",
    "    + ! batches: a tuple or list containg the features(input data) and labels(target data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iter = load_cifar10(True, train_augs, batch_size)\n",
    "test_iter = load_cifar10(False, test_augs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, (features, labels) in enumerate(train_iter):\n",
    "    y_pred = net(features)\n",
    "    y = labels\n",
    "    l = loss(y_pred, y)\n",
    "    ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch1_13",
   "language": "python",
   "name": "pytorch1_13"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
