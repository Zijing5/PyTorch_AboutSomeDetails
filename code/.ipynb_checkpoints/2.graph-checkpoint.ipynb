{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# partial derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "f(u,v)&=u^{3}+v^{2}+4uv\\\\\n",
    "\\frac{\\partial f}{\\partial u}&=3u^2+4v\\\\\n",
    "\\frac{\\partial f}{\\partial v}&=2v+4u\\\\\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = torch.tensor(1.,requires_grad=True)\n",
    "v = torch.tensor(1.1,requires_grad=True)\n",
    "f = u**3+v**2+4*u*v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(7.4000), tensor(6.2000))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u.grad,v.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(7.4000, grad_fn=<AddBackward0>),\n",
       " tensor(6.2000, grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3*u**2+4*v, 2*v+4*u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = torch.randn((3,3),requires_grad=True) # 输入\n",
    "\n",
    "w1 = torch.randn((3,3),requires_grad=True)\n",
    "w2 = torch.randn((3,3),requires_grad=True)\n",
    "w3 = torch.randn((3,3),requires_grad=True)\n",
    "w4 = torch.randn((3,3),requires_grad=True)\n",
    "\n",
    "b = w1*a\n",
    "c = w2*a\n",
    "b.retain_grad() # 保留任意非叶子节点的grad\n",
    "\n",
    "\n",
    "d = w3*b+w4*c\n",
    "d.retain_grad() # 保留非节点的grad\n",
    "L = (10-d).sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True, True, True, False, False, False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 叶子节点判断\n",
    "a.is_leaf,w1.is_leaf,w2.is_leaf,w3.is_leaf,w4.is_leaf,b.is_leaf,c.is_leaf,d.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WZJ\\AppData\\Local\\Temp\\ipykernel_15800\\3818454815.py:1: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\build\\aten\\src\\ATen/core/TensorBody.h:485.)\n",
      "  a.grad,w1.grad,w2.grad,w3.grad,w4.grad,b.grad,c.grad,d.grad\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.6098, -0.0092, -0.9854],\n",
       "         [ 0.1153,  0.9319,  0.8169],\n",
       "         [-1.0401, -2.6516, -1.0287]]),\n",
       " tensor([[-0.0107,  0.0560,  1.7147],\n",
       "         [-0.1481, -0.2835, -1.5371],\n",
       "         [-0.0901, -1.5422,  0.3346]]),\n",
       " tensor([[-0.0750,  0.1045, -1.2094],\n",
       "         [-0.0629, -0.1214,  0.7722],\n",
       "         [ 0.3354,  0.7568, -0.3161]]),\n",
       " tensor([[ 0.0729, -0.6633,  0.3995],\n",
       "         [-0.0373,  0.1844,  0.2654],\n",
       "         [-0.0745, -1.4104,  0.7463]]),\n",
       " tensor([[ 0.0263,  0.5928, -0.1647],\n",
       "         [ 0.4803,  0.2113, -0.5999],\n",
       "         [ 0.0320,  0.5227, -0.4859]]),\n",
       " tensor([[-0.1589, -0.0340, -1.8102],\n",
       "         [ 0.3199, -0.9804, -1.4885],\n",
       "         [-0.6954,  1.5663, -0.5344]]),\n",
       " None,\n",
       " tensor([[-1., -1., -1.],\n",
       "         [-1., -1., -1.],\n",
       "         [-1., -1., -1.]]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad,w1.grad,w2.grad,w3.grad,w4.grad,b.grad,c.grad,d.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b.grad\n",
    "-w3==b.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://github.com/hitdoggy/-PyTorch/blob/main/2_1.png?raw=true' width=35%>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch1_13",
   "language": "python",
   "name": "pytorch1_13"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
